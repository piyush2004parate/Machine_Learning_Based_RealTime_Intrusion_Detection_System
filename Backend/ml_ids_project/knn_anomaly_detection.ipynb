{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60baf1cc",
   "metadata": {},
   "source": [
    "# KNN-Based Network Intrusion Detection System\n",
    "## Detecting Normal vs Anomalous Packets using UNSW Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd8ea3b",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c469caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e771931a",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c7f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load UNSW training dataset\n",
    "print(\"Loading UNSW NB15 Training Dataset...\")\n",
    "df_train = pd.read_csv('UNSW_Train_Test Datasets/UNSW_NB15_training-set.csv')\n",
    "\n",
    "# Load UNSW testing dataset\n",
    "print(\"Loading UNSW NB15 Testing Dataset...\")\n",
    "df_test = pd.read_csv('UNSW_Train_Test Datasets/UNSW_NB15_testing-set.csv')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING DATASET INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Shape: {df_train.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df_train.head())\n",
    "print(f\"\\nData types:\\n{df_train.dtypes}\")\n",
    "print(f\"\\nMissing values:\\n{df_train.isnull().sum()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING DATASET INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Shape: {df_test.shape}\")\n",
    "print(f\"Data types:\\n{df_test.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a30dacc",
   "metadata": {},
   "source": [
    "## 3. Feature Selection and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d666babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature sets\n",
    "features = ['dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload',\n",
    "            'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'dtcpb',\n",
    "            'dwin', 'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'trans_depth', 'response_body_len',\n",
    "            'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm',\n",
    "            'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm', 'ct_srv_dst', 'is_sm_ips_ports']\n",
    "\n",
    "non_numeric = ['is_sm_ips_ports', 'is_ftp_login']\n",
    "numeric_features = list(set(features) - set(non_numeric))\n",
    "non_log = ['sttl', 'dttl', 'swin', 'dwin', 'trans_depth', 'ct_state_ttl', 'ct_flw_http_mthd']\n",
    "\n",
    "print(\"Feature preprocessing started...\")\n",
    "print(f\"Total features: {len(features)}\")\n",
    "print(f\"Non-numeric features: {len(non_numeric)}\")\n",
    "print(f\"Numeric features: {len(numeric_features)}\")\n",
    "\n",
    "# Apply log transform to training data\n",
    "df_logs_train = np.log10(df_train[list(set(numeric_features) - set(non_log))] + 1)\n",
    "df_numeric_train = pd.concat([df_logs_train, df_train[non_log]], axis=1)\n",
    "df_transformed_train = pd.concat([df_numeric_train, df_train[non_numeric]], axis=1)[features]\n",
    "\n",
    "# Apply log transform to testing data\n",
    "df_logs_test = np.log10(df_test[list(set(numeric_features) - set(non_log))] + 1)\n",
    "df_numeric_test = pd.concat([df_logs_test, df_test[non_log]], axis=1)\n",
    "df_transformed_test = pd.concat([df_numeric_test, df_test[non_numeric]], axis=1)[features]\n",
    "\n",
    "# Calculate mutual information for feature selection\n",
    "print(\"\\nCalculating mutual information scores...\")\n",
    "mi_arr = mutual_info_classif(X=df_transformed_train, y=df_train['label'], random_state=42)\n",
    "df_mi = pd.DataFrame(np.array([df_transformed_train.columns, mi_arr]).T, columns=['feature', 'mi'])\n",
    "df_mi['mi'] = df_mi['mi'].astype(float)\n",
    "df_mi = df_mi.sort_values('mi', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Features by Mutual Information:\")\n",
    "print(df_mi.head(15))\n",
    "\n",
    "# Select features with MI > 0.2\n",
    "mi_cutoff = 0.2\n",
    "selected_features = df_mi[df_mi['mi'] > mi_cutoff]['feature'].tolist()\n",
    "print(f\"\\nSelected {len(selected_features)} features with MI > {mi_cutoff}\")\n",
    "print(f\"Selected features: {selected_features}\")\n",
    "\n",
    "# Prepare final datasets\n",
    "df_train_processed = pd.concat([df_transformed_train[selected_features], df_train['label']], axis=1)\n",
    "df_test_processed = pd.concat([df_transformed_test[selected_features], df_test['label']], axis=1)\n",
    "\n",
    "print(\"\\nPreprocessing complete!\")\n",
    "print(f\"Training data shape: {df_train_processed.shape}\")\n",
    "print(f\"Testing data shape: {df_test_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78fceb0",
   "metadata": {},
   "source": [
    "## 4. Prepare Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cc4956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X_train = df_train_processed[selected_features]\n",
    "y_train = df_train_processed['label']\n",
    "\n",
    "X_test = df_test_processed[selected_features]\n",
    "y_test = df_test_processed['label']\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATA SPLIT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")\n",
    "print(f\"Number of features: {len(selected_features)}\")\n",
    "\n",
    "# Check label distribution\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LABEL DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTraining set:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"Normal packets: {(y_train == 0).sum()} ({(y_train == 0).sum()/len(y_train)*100:.2f}%)\")\n",
    "print(f\"Anomalous packets: {(y_train == 1).sum()} ({(y_train == 1).sum()/len(y_train)*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nTesting set:\")\n",
    "print(y_test.value_counts())\n",
    "print(f\"Normal packets: {(y_test == 0).sum()} ({(y_test == 0).sum()/len(y_test)*100:.2f}%)\")\n",
    "print(f\"Anomalous packets: {(y_test == 1).sum()} ({(y_test == 1).sum()/len(y_test)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3608b6fb",
   "metadata": {},
   "source": [
    "## 5. Standardize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1caeb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features using StandardScaler\n",
    "# KNN requires feature scaling because it uses distance metrics\n",
    "print(\"Standardizing features...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for easier handling\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=selected_features)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=selected_features)\n",
    "\n",
    "print(\"Feature standardization complete!\")\n",
    "print(f\"\\nTraining data statistics after scaling:\")\n",
    "print(f\"Mean: {X_train_scaled.mean().mean():.6f}\")\n",
    "print(f\"Std: {X_train_scaled.std().mean():.6f}\")\n",
    "print(f\"\\nSample of scaled data:\")\n",
    "print(X_train_scaled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0c898",
   "metadata": {},
   "source": [
    "## 6. Train KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66725e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train KNN classifier with n_neighbors=7 (determined from kSelection analysis)\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING KNN CLASSIFIER\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTraining KNN with n_neighbors=7...\")\n",
    "print(f\"Training samples: {len(X_train_scaled)}\")\n",
    "print(f\"Feature dimensions: {X_train_scaled.shape[1]}\")\n",
    "\n",
    "knn_model = KNN(n_neighbors=7, metric='euclidean', n_jobs=-1)\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nKNN Model trained successfully!\")\n",
    "print(f\"Model: {knn_model}\")\n",
    "print(f\"Classes: {knn_model.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae26105",
   "metadata": {},
   "source": [
    "## 7. Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fbb631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "print(\"=\"*60)\n",
    "print(\"GENERATING PREDICTIONS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nGenerating predictions on test set...\")\n",
    "\n",
    "y_pred = knn_model.predict(X_test_scaled)\n",
    "\n",
    "print(f\"Predictions generated for {len(y_pred)} test samples\")\n",
    "print(f\"\\nPrediction distribution:\")\n",
    "print(f\"Normal packets: {(y_pred == 0).sum()} ({(y_pred == 0).sum()/len(y_pred)*100:.2f}%)\")\n",
    "print(f\"Anomalous packets: {(y_pred == 1).sum()} ({(y_pred == 1).sum()/len(y_pred)*100:.2f}%)\")\n",
    "\n",
    "# Get prediction probabilities for additional analysis\n",
    "y_pred_proba = knn_model.predict_proba(X_test_scaled)\n",
    "print(f\"\\nPrediction probabilities shape: {y_pred_proba.shape}\")\n",
    "print(f\"Sample predictions with confidence:\")\n",
    "for i in range(5):\n",
    "    label = \"Normal\" if y_pred[i] == 0 else \"Anomalous\"\n",
    "    confidence = max(y_pred_proba[i]) * 100\n",
    "    print(f\"  Sample {i+1}: {label} (confidence: {confidence:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4766f895",
   "metadata": {},
   "source": [
    "## 8. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e2cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL PERFORMANCE EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nAccuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "print(f\"Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nRaw counts:\")\n",
    "print(cm)\n",
    "\n",
    "# Detailed breakdown\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nTrue Negatives (TN - Normal correctly identified):  {tn}\")\n",
    "print(f\"False Positives (FP - Normal misclassified as anomalous): {fp}\")\n",
    "print(f\"False Negatives (FN - Anomalous misclassified as normal): {fn}\")\n",
    "print(f\"True Positives (TP - Anomalous correctly identified):  {tp}\")\n",
    "\n",
    "# Additional metrics\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "print(f\"\\nSensitivity (True Positive Rate): {sensitivity:.4f} ({sensitivity*100:.2f}%)\")\n",
    "print(f\"Specificity (True Negative Rate): {specificity:.4f} ({specificity*100:.2f}%)\")\n",
    "\n",
    "# Summary table\n",
    "metrics_summary = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Sensitivity', 'Specificity'],\n",
    "    'Score': [accuracy, precision, recall, f1, sensitivity, specificity]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"METRICS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(metrics_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bac7fb",
   "metadata": {},
   "source": [
    "## 9. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768928db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: Confusion Matrix Heatmap\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[0],\n",
    "            xticklabels=['Normal', 'Anomalous'],\n",
    "            yticklabels=['Normal', 'Anomalous'])\n",
    "axes[0].set_title('KNN Confusion Matrix\\n(Test Set)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('True Label', fontweight='bold')\n",
    "axes[0].set_xlabel('Predicted Label', fontweight='bold')\n",
    "\n",
    "# Normalized confusion matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Greens', cbar=False, ax=axes[1],\n",
    "            xticklabels=['Normal', 'Anomalous'],\n",
    "            yticklabels=['Normal', 'Anomalous'])\n",
    "axes[1].set_title('KNN Confusion Matrix (Normalized)\\n(Test Set)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('True Label', fontweight='bold')\n",
    "axes[1].set_xlabel('Predicted Label', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('knn_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Confusion matrix visualization saved as 'knn_confusion_matrix.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecb5942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2: Performance Metrics Bar Chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'Sensitivity', 'Specificity']\n",
    "metrics_values = [accuracy, precision, recall, f1, sensitivity, specificity]\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "\n",
    "bars = ax.bar(metrics_names, metrics_values, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, value in zip(bars, metrics_values):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{value:.4f}\\n({value*100:.2f}%)',\n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_ylim([0, 1.1])\n",
    "ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title('KNN Model Performance Metrics\\n(UNSW Dataset)', fontsize=13, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('knn_metrics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Metrics visualization saved as 'knn_metrics.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d23fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3: Label Distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Actual label distribution\n",
    "actual_counts = pd.Series(y_test).value_counts()\n",
    "axes[0].bar(['Normal', 'Anomalous'], [actual_counts[0], actual_counts[1]], \n",
    "            color=['#2ca02c', '#d62728'], alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "axes[0].set_title('Actual Label Distribution\\n(Test Set)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Count', fontweight='bold')\n",
    "for i, (label, count) in enumerate([(0, actual_counts[0]), (1, actual_counts[1])]):\n",
    "    pct = count / len(y_test) * 100\n",
    "    axes[0].text(i, count, f'{count}\\n({pct:.1f}%)', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Predicted label distribution\n",
    "pred_counts = pd.Series(y_pred).value_counts()\n",
    "axes[1].bar(['Normal', 'Anomalous'], [pred_counts[0], pred_counts[1]], \n",
    "            color=['#1f77b4', '#ff7f0e'], alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "axes[1].set_title('Predicted Label Distribution\\n(Test Set)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Count', fontweight='bold')\n",
    "for i, (label, count) in enumerate([(0, pred_counts[0]), (1, pred_counts[1])]):\n",
    "    pct = count / len(y_pred) * 100\n",
    "    axes[1].text(i, count, f'{count}\\n({pct:.1f}%)', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('knn_label_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Label distribution visualization saved as 'knn_label_distribution.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcefc178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Create results summary\n",
    "results_summary = {\n",
    "    'model_info': {\n",
    "        'algorithm': 'K-Nearest Neighbors (KNN)',\n",
    "        'n_neighbors': 7,\n",
    "        'metric': 'euclidean',\n",
    "        'selected_features': selected_features,\n",
    "        'num_features': len(selected_features)\n",
    "    },\n",
    "    'dataset_info': {\n",
    "        'dataset': 'UNSW NB15',\n",
    "        'training_samples': len(X_train),\n",
    "        'testing_samples': len(X_test),\n",
    "        'total_samples': len(X_train) + len(X_test)\n",
    "    },\n",
    "    'performance_metrics': {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity\n",
    "    },\n",
    "    'confusion_matrix': {\n",
    "        'true_negatives': int(tn),\n",
    "        'false_positives': int(fp),\n",
    "        'false_negatives': int(fn),\n",
    "        'true_positives': int(tp)\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL TRAINING COMPLETE - SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(json.dumps(results_summary, indent=2))\n",
    "\n",
    "# Save summary\n",
    "with open('knn_model_summary.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(\"\\nSummary saved to 'knn_model_summary.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f513a4b3",
   "metadata": {},
   "source": [
    "## 11. Save Model for Project Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b3206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained KNN model and artifacts for backend integration\n",
    "import os\n",
    "import json\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SAVING MODEL ARTIFACTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define output directory\n",
    "model_dir = os.path.join('..', '..', 'model', 'unsw_tabular')\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(model_dir, 'model_knn.pkl')\n",
    "joblib.dump(knn_model, model_path)\n",
    "print(f\"✓ Model saved to: {model_path}\")\n",
    "\n",
    "# Save scaler\n",
    "scaler_path = os.path.join(model_dir, 'scaler_knn.pkl')\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"✓ Scaler saved to: {scaler_path}\")\n",
    "\n",
    "# Save selected features\n",
    "features_path = os.path.join(model_dir, 'features_knn.json')\n",
    "with open(features_path, 'w') as f:\n",
    "    json.dump({'selected_features': selected_features}, f, indent=2)\n",
    "print(f\"✓ Features saved to: {features_path}\")\n",
    "\n",
    "# Save metrics\n",
    "metrics_path = os.path.join(model_dir, 'metrics_knn.json')\n",
    "metrics_data = {\n",
    "    'accuracy': float(accuracy),\n",
    "    'precision': float(precision),\n",
    "    'recall': float(recall),\n",
    "    'f1_score': float(f1),\n",
    "    'sensitivity': float(sensitivity),\n",
    "    'specificity': float(specificity),\n",
    "    'n_neighbors': 7,\n",
    "    'n_features': len(selected_features),\n",
    "    'test_samples': len(y_test)\n",
    "}\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(metrics_data, f, indent=2)\n",
    "print(f\"✓ Metrics saved to: {metrics_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL ARTIFACTS READY FOR BACKEND INTEGRATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAll artifacts saved in: {os.path.abspath(model_dir)}\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(f\"  - model_knn.pkl (KNN classifier)\")\n",
    "print(f\"  - scaler_knn.pkl (StandardScaler)\")\n",
    "print(f\"  - features_knn.json (Selected features)\")\n",
    "print(f\"  - metrics_knn.json (Model metrics)\")\n",
    "print(\"\\nThe backend API can now load these artifacts for real-time predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a4eff",
   "metadata": {},
   "source": [
    "## 12. Project Integration Instructions\n",
    "\n",
    "The trained KNN model is now integrated with your Django backend. Here's how to use it:\n",
    "\n",
    "### Quick Start\n",
    "\n",
    "#### 1. API Endpoint Usage\n",
    "```\n",
    "POST /api/traffic/detect-anomaly/\n",
    "\n",
    "Request Body:\n",
    "{\n",
    "  \"features\": {\n",
    "    \"dur\": 0.5,\n",
    "    \"spkts\": 10,\n",
    "    \"dpkts\": 8,\n",
    "    \"sbytes\": 1024,\n",
    "    ...\n",
    "  }\n",
    "}\n",
    "\n",
    "Response:\n",
    "{\n",
    "  \"status\": \"success\",\n",
    "  \"prediction\": {\n",
    "    \"prediction\": 0,\n",
    "    \"label\": \"Normal\",\n",
    "    \"confidence\": 0.95,\n",
    "    \"probabilities\": {...}\n",
    "  },\n",
    "  \"severity\": \"Low\"\n",
    "}\n",
    "```\n",
    "\n",
    "#### 2. Python Integration\n",
    "```python\n",
    "from api.utils.knn_classifier import KNNAnomalyDetector\n",
    "\n",
    "detector = KNNAnomalyDetector(\n",
    "    model_path='path/to/model_knn.pkl',\n",
    "    features_path='path/to/features_knn.json',\n",
    "    scaler_path='path/to/scaler_knn.pkl'\n",
    ")\n",
    "\n",
    "result = detector.predict(features_dict)\n",
    "```\n",
    "\n",
    "#### 3. Django Command\n",
    "```bash\n",
    "python manage.py train_knn_model\n",
    "```\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. ✓ Model trained and saved\n",
    "2. → Test the API endpoint with sample data\n",
    "3. → Integrate with frontend\n",
    "4. → Set up real-time monitoring\n",
    "5. → Create alert system\n",
    "\n",
    "See `KNN_INTEGRATION_GUIDE.md` for detailed documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c547333",
   "metadata": {},
   "source": [
    "## 10. Sample Predictions and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481d1ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a detailed sample predictions table\n",
    "sample_size = 20\n",
    "sample_indices = np.random.choice(len(y_test), sample_size, replace=False)\n",
    "\n",
    "sample_data = pd.DataFrame({\n",
    "    'Actual': ['Normal' if y == 0 else 'Anomalous' for y in y_test.iloc[sample_indices]],\n",
    "    'Predicted': ['Normal' if y == 0 else 'Anomalous' for y in y_pred[sample_indices]],\n",
    "    'Normal_Prob': y_pred_proba[sample_indices, 0],\n",
    "    'Anomalous_Prob': y_pred_proba[sample_indices, 1],\n",
    "    'Confidence': np.max(y_pred_proba[sample_indices], axis=1),\n",
    "    'Correct': y_test.iloc[sample_indices].values == y_pred[sample_indices]\n",
    "})\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SAMPLE PREDICTIONS (20 random samples from test set)\")\n",
    "print(\"=\"*80)\n",
    "print(sample_data.to_string(index=False))\n",
    "\n",
    "# Calculate correctness\n",
    "correct_preds = (sample_data['Correct'].sum() / len(sample_data)) * 100\n",
    "print(f\"\\nCorrect predictions in sample: {correct_preds:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\"\"\n",
    "KNN Anomaly Detection Model Performance Summary:\n",
    "\n",
    "Dataset:\n",
    "  - UNSW NB15 Training Set Size: {len(X_train):,} packets\n",
    "  - UNSW NB15 Testing Set Size: {len(X_test):,} packets\n",
    "  - Selected Features: {len(selected_features)} (from {len(features)} total)\n",
    "\n",
    "Model Configuration:\n",
    "  - Algorithm: K-Nearest Neighbors (KNN)\n",
    "  - K Value: 7\n",
    "  - Distance Metric: Euclidean\n",
    "  - Feature Scaling: StandardScaler\n",
    "\n",
    "Performance Metrics:\n",
    "  - Accuracy:    {accuracy*100:6.2f}% (correctly classified packets)\n",
    "  - Precision:   {precision*100:6.2f}% (anomalies correctly identified)\n",
    "  - Recall:      {recall*100:6.2f}% (actual anomalies detected)\n",
    "  - F1-Score:    {f1:.4f}\n",
    "  - Sensitivity: {sensitivity*100:6.2f}% (true positive rate)\n",
    "  - Specificity: {specificity*100:6.2f}% (true negative rate)\n",
    "\n",
    "Classification Results:\n",
    "  - Total Test Packets: {len(y_test):,}\n",
    "  - Normal Packets (True Negatives): {tn:,} correctly classified, {fp:,} misclassified\n",
    "  - Anomalous Packets (True Positives): {tp:,} correctly detected, {fn:,} missed\n",
    "\n",
    "Key Takeaway:\n",
    "  The KNN model successfully detects {sensitivity*100:.1f}% of intrusions while maintaining\n",
    "  a {specificity*100:.1f}% normal traffic detection rate, making it effective for\n",
    "  real-time anomaly detection in network traffic.\n",
    "\"\"\")\n",
    "\n",
    "# Feature importance based on selection\n",
    "print(\"=\"*80)\n",
    "print(\"SELECTED FEATURES (by Mutual Information score)\")\n",
    "print(\"=\"*80)\n",
    "selected_mi = df_mi[df_mi['feature'].isin(selected_features)].sort_values('mi', ascending=False)\n",
    "print(selected_mi[['feature', 'mi']].to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
